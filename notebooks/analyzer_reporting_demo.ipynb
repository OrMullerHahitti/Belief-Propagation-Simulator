{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analyzer Reporting Demo (Random Graph)\n",
        "\n",
        "This notebook demonstrates the new analyzer/reporting workflow on a randomly generated factor graph. Each section highlights one of the core features added in the recent updates.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Setup\n",
        "\n",
        "We bring in the PropFlow builders, the snapshot recorder, and the reporting utilities. All computations run on a small random graph so they execute quickly in the notebook environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "from propflow import BPEngine, FGBuilder\n",
        "from propflow.configs import CTFactory\n",
        "from analyzer.snapshot_recorder import EngineSnapshotRecorder\n",
        "from analyzer.reporting import (\n",
        "    SnapshotAnalyzer,\n",
        "    AnalysisReport,\n",
        "    parse_snapshots,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build a Random Factor Graph and Capture Snapshots\n",
        "\n",
        "We use `FGBuilder.build_random_graph` with the integer cost-table factory. The engine runs for a handful of iterations while the recorder captures every message exchange.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Construct a small random factor graph\n",
        "np.random.seed(7)\n",
        "random_fg = FGBuilder.build_random_graph(\n",
        "    num_vars=6,\n",
        "    domain_size=3,\n",
        "    ct_factory=CTFactory.random_int.fn,\n",
        "    ct_params={'low': 0, 'high': 8},\n",
        "    density=0.6,\n",
        ")\n",
        "\n",
        "# Run a BP engine and capture per-step snapshots\n",
        "engine = BPEngine(factor_graph=random_fg)\n",
        "recorder = EngineSnapshotRecorder(engine)\n",
        "raw_snapshots = recorder.record_run(max_steps=5)\n",
        "len(raw_snapshots)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inspect the First Snapshot\n",
        "\n",
        "The recorder returns plain dictionaries. We take a quick look at the message keys and sample values before parsing them into typed records.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "first_snapshot = raw_snapshots[0]\n",
        "{\n",
        "    'step': first_snapshot['step'],\n",
        "    'message_count': len(first_snapshot['messages']),\n",
        "    'assignments': first_snapshot['assignments'],\n",
        "    'neutral_messages': first_snapshot['neutral_messages'],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Parse Snapshots and Register Factor Costs\n",
        "\n",
        "`parse_snapshots` validates step ordering, argmin metadata, and neutral counts. We also gather the factor cost tables so neutrality checks and split-ratio recommendations can use the correct thresholds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "records = parse_snapshots(raw_snapshots)\n",
        "len(records)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect factor cost tables from the original graph\n",
        "factor_tables = {\n",
        "    factor.name: np.asarray(factor.cost_table, dtype=float)\n",
        "    for factor in engine.factor_nodes\n",
        "}\n",
        "\n",
        "analyzer = SnapshotAnalyzer(records, max_cycle_len=6)\n",
        "for name, table in factor_tables.items():\n",
        "    analyzer.register_factor_cost(name, table)\n",
        "\n",
        "factor_tables.keys()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Belief Trajectories per Variable\n",
        "\n",
        "The analyzer reconstructs the argmin trajectory for each variable by aggregating factor-to-variable messages (mirroring the legacy visualizer logic).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "belief_series = analyzer.beliefs_per_variable()\n",
        "belief_series\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Difference Coordinates (\u0394Q, \u0394R)\n",
        "\n",
        "We recenter variable\u2192factor and factor\u2192variable messages into difference coordinates. Binary domains collapse to scalar gaps; multi-label domains are shifted so their minima start at zero.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "delta_q, delta_r = analyzer.difference_coordinates(step_idx=0)\n",
        "list(delta_q.items())[:3]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Jacobian Construction and Dependency Graph\n",
        "\n",
        "The Jacobian is built in difference coordinates. Small systems use dense matrices automatically; the dependency digraph captures the non-zero pattern for graph-based diagnostics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "J0 = analyzer.jacobian(step_idx=0)\n",
        "J0_dense = J0.toarray() if hasattr(J0, 'toarray') else np.asarray(J0)\n",
        "J0_dense\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dep_graph = analyzer.dependency_digraph(step_idx=0)\n",
        "{\n",
        "    'nodes': dep_graph.number_of_nodes(),\n",
        "    'edges': dep_graph.number_of_edges(),\n",
        "    'example_node': dep_graph.nodes[next(iter(dep_graph.nodes))],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Neutrality Checks and Greedy SCC Cover\n",
        "\n",
        "We certify a sample factor step and then run the SCC-based greedy cover routine to break all directed cycles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "record0 = records[0]\n",
        "q_messages = {\n",
        "    (msg.sender, msg.recipient): msg\n",
        "    for msg in record0.messages\n",
        "    if msg.flow == 'variable_to_factor'\n",
        "}\n",
        "\n",
        "sample_from_var, sample_factor = next(iter(q_messages.keys()))\n",
        "# Pick a target variable receiving from the same factor\n",
        "r_candidates = [\n",
        "    msg.recipient\n",
        "    for msg in record0.messages\n",
        "    if msg.flow == 'factor_to_variable' and msg.sender == sample_factor\n",
        "]\n",
        "\n",
        "sample_to_var = r_candidates[0]\n",
        "neutral_flag, winning_label = analyzer.neutral_step_test(\n",
        "    step_idx=0,\n",
        "    factor=sample_factor,\n",
        "    from_var=sample_from_var,\n",
        "    to_var=sample_to_var,\n",
        ")\n",
        "neutral_flag, winning_label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cover, residual = analyzer.scc_greedy_neutral_cover(step_idx=0, alpha={})\n",
        "cover, residual.number_of_nodes(), residual.number_of_edges()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Nilpotent Bounds, Block Norms, Cycles, and Split Ratios\n",
        "\n",
        "The analyzer reports the nilpotent index (when it exists), the DAG longest-path bound, block norms consistent with the engine snapshot manager, cycle statistics, and heuristic split-ratio recommendations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nilpotent = analyzer.nilpotent_index(0)\n",
        "dag_bound = analyzer._dag_bound_cache.get(0)\n",
        "block_norms = analyzer.block_norms(0)\n",
        "cycle_info = analyzer.cycle_metrics(0)\n",
        "ratios = analyzer.recommend_split_ratios(0)\n",
        "{\n",
        "    'nilpotent_index': nilpotent,\n",
        "    'dag_bound': dag_bound,\n",
        "    'block_norms': block_norms,\n",
        "    'cycle_metrics': cycle_info,\n",
        "    'recommended_alpha': ratios,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Reporting Artefacts (JSON / CSV / Plots)\n",
        "\n",
        "`AnalysisReport` bundles the analyzer results into reusable exports. The example below writes JSON and CSV summaries and produces belief/dependency plots under `results/analyzer_demo`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "report = AnalysisReport(analyzer)\n",
        "summary = report.to_json(step_idx=0)\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = Path('results/analyzer_demo')\n",
        "report.to_csv(output_dir, step_idx=0)\n",
        "report.plots(output_dir, step_idx=0, include_graph=True)\n",
        "sorted(p.name for p in output_dir.iterdir())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. CLI Reference\n",
        "\n",
        "Run the same analysis from the terminal with the dedicated entry point:\n",
        "\n",
        "````\n",
        "bp-analyze \\\n",
        "  --snapshots results/run.json \\\n",
        "  --out results/analyzer_demo \\\n",
        "  --step 0 \\\n",
        "  --compute-jac \\\n",
        "  --cover \\\n",
        "  --plot\n",
        "````\n",
        "\n",
        "This command mirrors the notebook flow: it parses snapshots, builds the analyzer, exports summaries, and optionally writes the Jacobian and neutral cover information.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}