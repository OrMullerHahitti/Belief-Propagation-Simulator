{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft-Min Torch Computator Walkthrough\n",
    "\n",
    "This notebook explains how the differentiable `SoftMinTorchComputator` integrates with `BPEngine`, mirroring the example script while adding diagnostic comparisons against the classic Min-Sum variant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You Will Learn\n",
    "\n",
    "- Instantiate the same cycle graph used in the example script with deterministic cost tables.\n",
    "- Run the PropFlow `BPEngine` twice: once with the soft-min torch computator and once with Min-Sum.\n",
    "- Inspect variable assignments, global costs, and individual messages to see how soft-min smooths hard minimum operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy for deterministic random number handling.\n",
    "import numpy as np\n",
    "# Import torch to exercise the differentiable computator (raises ImportError if missing).\n",
    "import torch\n",
    "# Import the PropFlow engine and factor graph builder to mirror the example script.\n",
    "from propflow import BPEngine, FGBuilder\n",
    "# Import the classic Min-Sum computator for baseline comparisons.\n",
    "from propflow.bp.computators import MinSumComputator\n",
    "# Import the SoftMinTorchComputator showcased in the new example test.\n",
    "from propflow.nn.torch_computators import SoftMinTorchComputator\n",
    "# Quick sanity check to confirm torch exposes the Tensor class before continuing.\n",
    "assert hasattr(torch, \"Tensor\"), \"PyTorch must be installed to run this notebook.\"\n",
    "# Seed numpy so generated cost tables remain reproducible across runs.\n",
    "np.random.seed(7)\n",
    "# Seed torch so any tensor-based randomness is repeatable as well.\n",
    "torch.manual_seed(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Deterministic Cycle Graph\n",
    "\n",
    "We reproduce the five-variable cycle used in `examples/torch_softmin_demo.py`, but we seed the cost tables so every run stays identical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper for building the small cycle graph demonstrated below.\n",
    "def build_demo_cycle_graph(seed: int, num_vars: int = 5, domain: int = 3):\n",
    "    # Initialize a dedicated RNG so generated cost tables stay reproducible.\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Define a local factory that mirrors the integer cost table generator from the example script.\n",
    "    def seeded_cost_table(n: int, domain_size: int, low: int = 1, high: int = 20):\n",
    "        # Draw integer-valued costs and expose them as floating point arrays for the computators.\n",
    "        return rng.integers(low=low, high=high, size=(domain_size,) * n).astype(float)\n",
    "    # Build the cycle graph via FGBuilder so structure matches the example topology.\n",
    "    graph = FGBuilder.build_cycle_graph(\n",
    "        num_vars=num_vars,\n",
    "        domain_size=domain,\n",
    "        ct_factory=seeded_cost_table,\n",
    "        ct_params={\"low\": 1, \"high\": 20},\n",
    "    )\n",
    "    # Return the freshly built factor graph so callers get an independent copy.\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Both Engines\n",
    "\n",
    "We now create two independent graphs and run the BP engine with the soft-min and Min-Sum computators respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh factor graph for the differentiable engine so that message state starts cleanly.\n",
    "soft_graph = build_demo_cycle_graph(seed=21)\n",
    "# Mirror the same graph for the Min-Sum baseline to compare outputs fairly.\n",
    "minsum_graph = build_demo_cycle_graph(seed=21)\n",
    "# Instantiate the SoftMinTorchComputator with a low temperature to approximate hard min-sum behavior.\n",
    "soft_computator = SoftMinTorchComputator(tau=1e-2, device=\"cpu\")\n",
    "# Instantiate the classic Min-Sum computator as the reference implementation.\n",
    "minsum_computator = MinSumComputator()\n",
    "# Create the Soft-Min BP engine and enable per-step history captures for analysis.\n",
    "soft_engine = BPEngine(factor_graph=soft_graph, computator=soft_computator, use_bct_history=True)\n",
    "# Create the Min-Sum BP engine with the same history configuration for apples-to-apples comparisons.\n",
    "minsum_engine = BPEngine(factor_graph=minsum_graph, computator=minsum_computator, use_bct_history=True)\n",
    "# Run the soft-min engine for a modest number of iterations without persisting history artifacts.\n",
    "soft_engine.run(max_iter=10, save_json=False, save_csv=False)\n",
    "# Run the Min-Sum engine with identical runtime settings.\n",
    "minsum_engine.run(max_iter=10, save_json=False, save_csv=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Assignments and Global Cost\n",
    "\n",
    "With both engines executed, we verify they converge to the same assignments and overall objective value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture the final assignments produced by the soft-min engine.\n",
    "soft_assignments = soft_engine.assignments\n",
    "# Capture the final assignments produced by the Min-Sum baseline.\n",
    "minsum_assignments = minsum_engine.assignments\n",
    "# Pull the final global cost from the soft-min engine for comparison.\n",
    "soft_cost = soft_engine.graph.global_cost\n",
    "# Pull the final global cost from the Min-Sum engine as the reference.\n",
    "minsum_cost = minsum_engine.graph.global_cost\n",
    "# Display the assignments so we can verify they match exactly.\n",
    "print(\"Soft-min assignments:\", soft_assignments)\n",
    "# Display the baseline assignments for side-by-side inspection.\n",
    "print(\"Min-Sum assignments:\", minsum_assignments)\n",
    "# Display the global costs to confirm the objectives coincide.\n",
    "print(\"Soft-min global cost:\", soft_cost)\n",
    "# Display the baseline cost for direct comparison.\n",
    "print(\"Min-Sum global cost:\", minsum_cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Individual Messages\n",
    "\n",
    "The soft-min computator smooths the hard minimum. By exploring the recorded messages from the first BP step, we can see how closely the softened values match Min-Sum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the recorded per-step messages from the soft-min engine history.\n",
    "soft_step_messages = soft_engine.history.step_messages\n",
    "# Select the first step to inspect the earliest factor-to-variable communication.\n",
    "soft_first_step = soft_step_messages.get(0, [])\n",
    "# Filter the messages to those originating from factor nodes so we focus on R messages.\n",
    "soft_factor_messages = [msg for msg in soft_first_step if msg.sender.startswith(\"f\")]\n",
    "# Ensure we have at least one factor message to inspect.\n",
    "assert soft_factor_messages, \"Expected at least one factor message in step 0.\"\n",
    "# Pick the first factor message for detailed inspection.\n",
    "soft_sample_message = soft_factor_messages[0]\n",
    "# Repeat the same logging extraction for the Min-Sum baseline.\n",
    "minsum_step_messages = minsum_engine.history.step_messages\n",
    "# Select the same chronological step for the baseline engine.\n",
    "minsum_first_step = minsum_step_messages.get(0, [])\n",
    "# Build a lookup keyed by (sender, recipient) so we can match the same edge.\n",
    "minsum_lookup = {\n",
    "    (msg.sender, msg.recipient): msg\n",
    "    for msg in minsum_first_step\n",
    "}\n",
    "# Fetch the corresponding baseline message using the same sender and recipient identifiers.\n",
    "minsum_sample_message = minsum_lookup[(soft_sample_message.sender, soft_sample_message.recipient)]\n",
    "# Convert the stored message payload into a numpy array for the soft-min engine.\n",
    "soft_vector = np.array(soft_sample_message.data)\n",
    "# Convert the baseline payload into a numpy array as well.\n",
    "minsum_vector = np.array(minsum_sample_message.data)\n",
    "# Compute the element-wise difference to illustrate the soft-min smoothing behavior.\n",
    "difference_vector = soft_vector - minsum_vector\n",
    "# Print the soft-min message values for inspection.\n",
    "print(\"Soft-min R message:\", soft_vector)\n",
    "# Print the Min-Sum message values for side-by-side comparison.\n",
    "print(\"Min-Sum R message:\", minsum_vector)\n",
    "# Print the difference so we can quantify how closely the soft approximation tracks the hard minimum.\n",
    "print(\"Difference (soft - min):\", difference_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "- The soft-min torch computator matches Min-Sum assignments and global cost while remaining differentiable.\n",
    "- Message traces reveal the soft-min outputs shadow the hard min values with minor smoothing that depends on the temperature `tau`.\n",
    "- You can lower `tau` for closer agreement or raise it when smoother gradients are required for learning workflows.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}